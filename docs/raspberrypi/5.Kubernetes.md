# k8s
kubernetes是一个开源的容器编排引擎，用于对容器化应用进行自动化部署、扩缩容、滚动升级等。   
主节点的核心组件有API Server（负责提供RESTful形式的Kunernetes API服务）、Controller Manager（负责维护集群状态：故障检测、自动扩展、滚动更新）、Scheduler（负责监听和新建Pod）、Etcd（负责存储资源对象状态信息、网络配置）。   
工作节点的kubelet组件用于确保容器在pod正常运行，kube-proxy组件作为网络代理，container runtime用于运行容器。   
附加组件有Coredns为集群提供DNS服务，Flannel提供跨节点的Pod之间通讯服务，Nginx Ingress为服务提供外网入口，Heapster提供资源监控，Dashboard提供k8s的Web 控制台界面

# k3s
k3s为物联网、边缘计算及ARM等类型设备做了优化，减少k8s的内存占用(server端最低512M，agent端最低75M)，减少应用本身体积。    
服务器节点运行k3s server，工作节点运行k3s agent。如果要做到k3s的高可用，需使用多个服务节点，并使用外部数据库。

## 服务器节点安装
```sh
curl -sfL https://get.k3s.io | sh -
# k3s默认容器为containerd，通过以下命令替换上面的命令可切换到docker。
# curl -sfL https://get.k3s.io | sh -s - server --docker
# 或者修改/etc/systemd/system/multi-user.target.wants/k3s.service，将ExecStart值改成“/usr/local/bin/k3s server --docker --no-deploy traefik”
# [INFO]  Finding release for channel stable
# [INFO]  Using v1.18.9+k3s1 as release
# [INFO]  Downloading hash https://github.com/rancher/k3s/releases/download/v1.18.9+k3s1/sha256sum-arm.txt
# [INFO]  Downloading binary https://github.com/rancher/k3s/releases/download/v1.18.9+k3s1/k3s-armhf
# [INFO]  Verifying binary download
# [INFO]  Installing k3s to /usr/local/bin/k3s
# [INFO]  Creating /usr/local/bin/kubectl symlink to k3s
# [INFO]  Creating /usr/local/bin/crictl symlink to k3s
# [INFO]  Skipping /usr/local/bin/ctr symlink to k3s, command exists in PATH at /usr/bin/ctr
# [INFO]  Creating killall script /usr/local/bin/k3s-killall.sh
# [INFO]  Creating uninstall script /usr/local/bin/k3s-uninstall.sh
# [INFO]  env: Creating environment file /etc/systemd/system/k3s.service.env
# [INFO]  systemd: Creating service file /etc/systemd/system/k3s.service
# [INFO]  systemd: Enabling k3s unit
# Created symlink /etc/systemd/system/multi-user.target.wants/k3s.service → /etc/systemd/system/k3s.service.
# [INFO]  systemd: Starting k3s
sudo kubectl get nodes
# 解决拉取镜像时报非权威证书受信任问题: certificate signed by unknown authority
sudo curl -X GET https://letsencrypt.org/certs/lets-encrypt-x3-cross-signed.pem --output /etc/ssl/certs/lets-encrypt-x3-cross-signed.pem
sudo curl -X GET https://letsencrypt.org/certs/isrgrootx1.pem --output /etc/ssl/certs/isrgrootx1.pem
# 卸载k3s
# /usr/local/bin/k3s-uninstall.sh
```

## 工作节点安装
```sh
# k3s-master指向服务器节点，可编辑/etc/hosts达到
K3S_URL="https://k3s-master:6443"
sudo cat /var/lib/rancher/k3s/server/node-token
# token从上面命令的输出获取
K3S_TOKEN="::node::"
curl -sfL https://get.k3s.io | K3S_URL=${K3S_URL} K3S_TOKEN=${K3S_TOKEN} sh -
# 或者下载到本地执行：k3s-armhf agent --server $K3S_URL --token $K3S_TOKEN
# alias docker='k3s crictl'
# kubectl get pod
# 解决拉取镜像时报非权威证书受信任问题
sudo curl -X GET https://letsencrypt.org/certs/lets-encrypt-x3-cross-signed.pem --output /etc/ssl/certs/lets-encrypt-x3-cross-signed.pem
sudo curl -X GET https://letsencrypt.org/certs/isrgrootx1.pem --output /etc/ssl/certs/isrgrootx1.pem
# 卸载k3s agent
# /usr/local/bin/k3s-agent-uninstall.sh
```

## 服务节点安装kubernetes-dashboard
```sh
kubectl apply -f https://github.com/kubernetes/dashboard/blob/master/aio/deploy/recommended.yaml
# 某些版本的部署脚本使用了被墙的域名k8s.gcr.io，可以将部署配置下载到本地后编辑替换成registry.aliyuncs.com/google_containers
kubectl get pod --all-namespaces --show-labels
# 如果状态异常，可以查看失败原因
# kubectl -n kubernetes-dashboard describe pod kubernetes-dashboard
# 创建登入用户，并绑定到角色: https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard

---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
EOF
# 查看token
kubectl -n kubernetes-dashboard describe secret admin-user-token | grep ^token
# 启用本地代理
kubectl proxy
# 访问http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/
# 输入之前显示的token，点击登入
# 删除pod，删除namespace
# kubectl -n kubernetes-dashboard delete pod -l k8s-app=kubernetes-dashboard
# kubectl delete ns kubernetes-dashboard
```
## 使用dashboard部署

```sh
# 创建Secret
apiVersion: v1
kind: Secret
metadata:
  name: registry-secret
type: kubernetes.io/basic-auth
stringData: # data的值为base64编码： echo -n 'myusername' | base64
  username: myusername
  password: mypassword

#---

# 创建部署
#cat > app.yml << "EOF"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app# 部署名称
  namespace: default
  labels:
    app: app-name # 部署标签
spec:
  replicas: 2 #部署副本数
  selector:
    matchLabels:
      app: app-name
  template:
    metadata:
      labels:
        app: app-name # 标签必须与spec.selector.matchLabels相同
    spec:
      imagePullSecrets:
        name: registry-secret
      nodeSelector: # 可以简单使用nodeName来指定节点，但对于一些自动生成节点名称的不好处理。或者配置affinity，根据亲和性选择节点！
        kubernetes.io/arch: amd64 # 知名标签：arch, os, hostname。可通过命令给节点增加标签：kubectl label nodes <node-name> <label-key>=<label-value>	  
      containers:
        - name: container-name
          image: hub.iamwhatiam.ml:5000/repoName/imageName:imageVersion # 使用域名，镜像注册服务需启用SSL，非权威证书需将根证书导入/etc/ssl/certs/
          env:
            - name: SPRING_PROFILES_ACTIVE
              value: dev
            - name: INSTANCE_NAME
              valueFrom: 
                fieldRef:
                  fieldPath: spec.nodeName
# k8s的启动命令和启动参数会覆盖容器镜像中自带的命令与参数
          command: # remote debug: $CATALINA_HOME/bin/catalina jpda start
            - java
          args:
            - '-Xdebug'
            - '-Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000'
#            - '-agentlib:jdwp=transport=dt_socket,address=8000,server=y,suspend=n'
            - '-jar'
            - 'spring.application.name.jar'
          ports:
            - containerPort: 8080
              protocol: HTTP
            - containerPort: 8000
              protocol: TCP
          resources: # 请求和限制都不存在时，QoS类型为BestEffort；请求小于限制时，QoS类型为Burstable；请求等于限制时，QoS类型为Guaranteed
            limits:
              memory: "1024Mi"
              cpu: "1"
            requests:
              memory: "512Mi"
              cpu: 1000m
          startupProbe: # 启动探测
            tcpSocket:
              port: 8080
            failureThreshold: 3 # 探测失败时，Kubernetes 的重试次数
            periodSeconds: 10 # 执行探测的时间间隔（单位是秒）
          livenessProbe: # 非存活时pod会被kill
            httpGet:
              port: 8080
              path: /actuator/health/liveness
            initialDelaySeconds: 0 # 第一次探测前等待时间
            periodSeconds: 5
          readinessProbe: # 就绪才会接收流量
            httpGet:
              port: 8080
              path: /actuator/health/readiness
            initialDelaySeconds: 30
            periodSeconds: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailabel: 25%
      maxSurge: 25%
#EOF
```

参考：

1. [k8s](https://kubernetes.io/docs/concepts/overview/components/)
2. [k3s](https://rancher.com/docs/k3s/latest/en/)
